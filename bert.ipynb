{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\charl\\miniconda3\\envs\\mat099\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, TFBertForQuestionAnswering\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"dmis-lab/biobert-base-cased-v1.1-squad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForQuestionAnswering.\n",
      "\n",
      "All the weights of TFBertForQuestionAnswering were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForQuestionAnswering for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "model = TFBertForQuestionAnswering.from_pretrained(\"dmis-lab/biobert-base-cased-v1.1-squad\", from_pt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What reduces risk of Covid-19?\"\n",
    "text = \"\"\"\n",
    "Coronavirus (COVID-19) can make anyone seriously ill. But for some people, the risk is higher.\n",
    "At some point during the COVID-19 pandemic you may have been told you were at high risk of getting seriously ill from COVID-19 (sometimes called clinically vulnerable or clinically extremely vulnerable). You may also have been advised to stay at home (shield).\n",
    "For most people at high risk from COVID-19, vaccination has significantly reduced this risk. You can follow the same advice as everyone else on how to avoid catching and spreading COVID-19.\n",
    "Some people continue to be at high risk from COVID-19, despite vaccination.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(question, text, return_tensors=\"tf\")\n",
    "outputs = model(**inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_start_index = int(tf.math.argmax(outputs.start_logits, axis=-1)[0])\n",
    "answer_end_index = int(tf.math.argmax(outputs.end_logits, axis=-1)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_answer_tokens = inputs.input_ids[0, answer_start_index : answer_end_index + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'vaccination'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(predict_answer_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Potential approach for TF-IDF cosine similarity:\n",
    "1. Extraction of titles from all JSON documents.\n",
    "2. Getting the list of embeddings for all the titles using BERT.\n",
    "3. Finding the embedding for the input query using BERT\n",
    "4. Using Cosine similarity, to find the list of similar embeddings to that of input query. This generate the list of titles which are similar to the input query. \n",
    "\n",
    "Could extend this to search in the text body after. Recommend starting with a small amount of self-generated text to test approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"Data/clean_pmc.csv\", nrows=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_null_data = data[data['abstract'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(662, 9)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "not_null_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_answer(question, text):\n",
    "    \n",
    "    inputs = tokenizer(question, text, return_tensors=\"tf\")\n",
    "    outputs = model(**inputs)\n",
    "    answer_start_index = int(tf.math.argmax(outputs.start_logits, axis=-1)[0])\n",
    "    answer_end_index = int(tf.math.argmax(outputs.end_logits, axis=-1)[0])\n",
    "    predict_answer_tokens = inputs.input_ids[0, answer_start_index : answer_end_index + 1]\n",
    "    predicted_answer = tokenizer.decode(predict_answer_tokens)\n",
    "\n",
    "    return predicted_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 662/662 [43:11<00:00,  3.91s/it]  \n"
     ]
    }
   ],
   "source": [
    "question = \"What are the risk factors of Covid-19?\"\n",
    "\n",
    "qa_results=[]\n",
    "for index, row in tqdm(not_null_data.iterrows(), total=not_null_data.shape[0]):\n",
    "\n",
    "    if len(tokenizer.tokenize(row['abstract'])) < 475:\n",
    "        \n",
    "        text = row['abstract']\n",
    "        predicted_answer = get_answer(question, text)\n",
    "        \n",
    "        if predicted_answer != '[CLS]' and predicted_answer != '':\n",
    "            qa_results.append((index, predicted_answer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['outputs/bert_qa_results_500.pkl']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(qa_results, 'outputs/bert_qa_results_500.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.load('outputs/bert_qa_results_500.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_risk_factors = [\n",
    "    'age', 'gender', 'sex', 'pneumonia', 'obesity', 'weight', 'diabetes', 'smoking', 'cardiovascular', 'location', 'contact', 'asthma', 'down\\'s syndrome', 'cancer', 'sickle cell'\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['age', 'asthma', 'age', 'age', 'age', 'contact', 'age', 'pneumonia', 'age', 'age', 'age', 'age', 'age', 'age', 'pneumonia', 'age', 'age', 'age', 'age', 'sex', 'age', 'age', 'cancer', 'age', 'age', 'asthma', 'age']\n"
     ]
    }
   ],
   "source": [
    "risk_factor_list=[]\n",
    "for result in qa_results:\n",
    "    for risk_factor in candidate_risk_factors:\n",
    "        if risk_factor in result[1]:\n",
    "            risk_factor_list.append(risk_factor)\n",
    "print(risk_factor_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'age': 20,\n",
       "         'asthma': 2,\n",
       "         'contact': 1,\n",
       "         'pneumonia': 2,\n",
       "         'sex': 1,\n",
       "         'cancer': 1})"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(risk_factor_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Next steps**:\n",
    "\n",
    "- Take subsample of data (first 5 rows) and try extracting answers. Use abstracts rather than body text to overcome 512 token limit.\n",
    "- Write code to truncate to 512 tokens for if abstracts are bigger.\n",
    "- Recreate plan to extract most commonly mentioned risk factors (may have to adjust list of risk factors to match returns from sample data).\n",
    "- Plan how to return candidate papers once BERT methodology (above steps) is determined."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.0 ('mat099')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bc1d07306176b222eaafa12c90663e0030376ae09cf08833d8be3832e6c88b0d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
